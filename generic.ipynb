{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stm32ai-modelzoo train/build/generate\n",
    "\n",
    "This Jupyter notebook invokes the Vespucci jobcontrol-api to\n",
    "\n",
    "- Train the model \n",
    "- Benchmark the model and generate the network `.c`/`.h` sources\n",
    "- Build the application firmware\n",
    "\n",
    "### Initial setup\n",
    "\n",
    "Dependencies are managed via the `poetry` command. You may install it with `pip install poetry`\n",
    "\n",
    "Then, install all dependencies simply by invoking `poetry install` in this directory. This will create a virtual environment and place it in this folder as `.venv`.\n",
    "\n",
    "Start a jupyter kernel in that environment and you're ready to run the notebook.\n",
    "\n",
    "You will need API credentials for Vespucci. This example runs on vespucci-dev by default, so you should use a token generated for that environment. Retrieve an id token and place it into a `token.txt` file in the working directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration preamble\n",
    "import json\n",
    "import httpx\n",
    "import config\n",
    "import utils\n",
    "import asyncio\n",
    "import zipfile as zf\n",
    "import io\n",
    "\n",
    "from collections.abc import Awaitable\n",
    "\n",
    "client = httpx.Client(timeout=300, headers=utils.headers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "This step will produce the model artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating training job\")\n",
    "\n",
    "job = (\n",
    "    client.post(\n",
    "        config.JOBCONTROL_API_JOBS_ENDPOINT,\n",
    "        files={\n",
    "            \"uploadedFile\": (\n",
    "                \"train_data\",\n",
    "                open(\"./sample-inputs/object_detection/train.zip\", \"rb\"),\n",
    "            ),\n",
    "            \"uploadedFile2\": (\n",
    "                \"valid_data\",\n",
    "                open(\"./sample-inputs/object_detection/valid.zip\", \"rb\"),\n",
    "            ),\n",
    "        },\n",
    "        data={\n",
    "            \"templateId\": config.TRAINING_JOB_TEMPLATE_ID,\n",
    "            \"runtimeInput\": json.dumps(\n",
    "                {\n",
    "                    \"job_config\": {\"root\": \"object_detection/scripts/training\"},\n",
    "                    \"training_config\": {\n",
    "                        \"hydra\": {\"run\": {\"dir\": \"outputs\"}},\n",
    "                        \"stm32ai\": {\"version\": \"8.0.1\"},\n",
    "                        \"dataset\": {\"class_names\": [\"person\"]},\n",
    "                    },\n",
    "                }\n",
    "            ),\n",
    "        },\n",
    "    )\n",
    "    .raise_for_status()\n",
    "    .json()\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Created training job: {job!r}\")\n",
    "\n",
    "job_id = job[\"id\"]\n",
    "\n",
    "print(\"Blocking until job is done...\")\n",
    "job = await utils.block_until_done(job_id)\n",
    "\n",
    "print(\"Training job is done. Downloading artifacts\")\n",
    "artifacts = utils.download_artifacts(job)\n",
    "\n",
    "client.delete(f\"{config.JOBCONTROL_API_JOBS_ENDPOINT}/{job_id}\")\n",
    "\n",
    "outputs_zip = zf.ZipFile(io.BytesIO(artifacts[\"outputs_zip\"]), \"r\")\n",
    "\n",
    "model = outputs_zip.read(\"quantized_models/quantized_model.tflite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking + Cube.AI\n",
    "\n",
    "This step will generate `.c`/`.h` NN sources by invoking the STM32 Developer cloud APIs.\n",
    "\n",
    "We'll download a zip containing said sources as well as the CubeAI runtime that will eventually be linked into the application firmware.\n",
    "\n",
    "Simultaneously, we'll dispatch the benchmarkinging job and display the inference time once it's been measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devcloud API command\n",
    "generate_command = {\n",
    "    \"command\": \"generate\",\n",
    "    \"arguments\": {\n",
    "        \"options\": {\n",
    "            \"includeLibraryForSerie\": \"H7\",\n",
    "            \"includeLibraryForIde\": \"gcc\",\n",
    "            \"allocateInputs\": True,\n",
    "            \"allocateOutputs\": True,\n",
    "            \"compression\": \"none\",\n",
    "            \"optimization\": \"balanced\",\n",
    "            \"classifier\": False,\n",
    "        },\n",
    "    },\n",
    "    \"version\": \"8.0.1\",\n",
    "}\n",
    "\n",
    "print(\"Creating Cube.AI job\")\n",
    "generate_job = (\n",
    "    client.post(\n",
    "        config.JOBCONTROL_API_JOBS_ENDPOINT,\n",
    "        files={\n",
    "            \"model\": (\"model\", model),\n",
    "        },\n",
    "        data={\n",
    "            \"templateId\": config.CUBEAI_JOB_TEMPLATE_ID,\n",
    "            \"runtimeInput\": json.dumps({\"command\": generate_command}),\n",
    "        },\n",
    "    )\n",
    "    .raise_for_status()\n",
    "    .json()\n",
    ")\n",
    "print(f\"Created CubeAI job: {generate_job!r}\")\n",
    "\n",
    "# devcloud API command\n",
    "benchmarking_command = {\n",
    "    \"command\": \"benchmark\",\n",
    "    \"arguments\": {\"options\": {}, \"parameters\": {\"board_name\": \"STM32H747I-DISCO\"}},\n",
    "    \"version\": \"8.0.1\",\n",
    "}\n",
    "\n",
    "print(\"Creating benchmarking job\")\n",
    "benchmarking_job = (\n",
    "    client.post(\n",
    "        config.JOBCONTROL_API_JOBS_ENDPOINT,\n",
    "        files={\n",
    "            \"model\": (\"model\", model),\n",
    "        },\n",
    "        data={\n",
    "            \"templateId\": config.BENCHMARKING_JOB_TEMPLATE_ID,\n",
    "            \"runtimeInput\": json.dumps({\"command\": benchmarking_command}),\n",
    "        },\n",
    "    )\n",
    "    .raise_for_status()\n",
    "    .json()\n",
    ")\n",
    "print(f\"Created benchmarking job: {benchmarking_job!r}\")\n",
    "\n",
    "\n",
    "async def _generate_coro() -> Awaitable[None]:\n",
    "    global generate_job\n",
    "    global cubeai_output\n",
    "\n",
    "    job_id = generate_job[\"id\"]\n",
    "\n",
    "    generate_job = await utils.block_until_done(job_id)\n",
    "\n",
    "    print(\"CubeAI job is done. Downloading artifacts\")\n",
    "    artifacts = utils.download_artifacts(generate_job)\n",
    "    client.delete(f\"{config.JOBCONTROL_API_JOBS_ENDPOINT}/{job_id}\")\n",
    "\n",
    "    cubeai_output = artifacts[\"output\"]\n",
    "\n",
    "\n",
    "async def _benchmarking_coro() -> Awaitable[None]:\n",
    "    global benchmarking_job\n",
    "    global benchmarking_output\n",
    "\n",
    "    job_id = benchmarking_job[\"id\"]\n",
    "\n",
    "    benchmarking_job = await utils.block_until_done(job_id)\n",
    "\n",
    "    print(f\"Benchmarking job is done. Downloading artifacts\")\n",
    "    artifacts = utils.download_artifacts(benchmarking_job)\n",
    "    client.delete(f\"{config.JOBCONTROL_API_JOBS_ENDPOINT}/{job_id}\")\n",
    "\n",
    "    benchmarking_output = artifacts[\"output\"]\n",
    "\n",
    "    with zf.ZipFile(io.BytesIO(benchmarking_output), \"r\") as archive:\n",
    "        report = json.loads(archive.read(\"benchmark_report.json\").decode(\"utf-8\"))\n",
    "        print(f\"Benchmarking job is done. Inference time: {report['duration_ms']}ms\")\n",
    "\n",
    "await asyncio.wait(\n",
    "    (asyncio.create_task(_generate_coro()), asyncio.create_task(_benchmarking_coro()))\n",
    ")\n",
    "\n",
    "print(\"Cube.AI and benchmarking done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building\n",
    "\n",
    "In this step we build the output NN sources into a deployment-ready application firmware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating builder job\")\n",
    "job = (\n",
    "    client.post(\n",
    "        config.JOBCONTROL_API_JOBS_ENDPOINT,\n",
    "        files={\"file1\": (\"cubeai_output\", cubeai_output), \"file2\": (\"model\", model)},\n",
    "        data={\n",
    "            \"templateId\": config.COMPILATION_JOB_TEMPLATE_ID,\n",
    "            \"runtimeInput\": json.dumps(\n",
    "                {\n",
    "                    \"job_config\": {\"root\": \"object_detection/scripts/deployment\"},\n",
    "                    \"build_config\": {\n",
    "                        \"stm32ai\": {\"version\": \"8.0.1\"},\n",
    "                        \"dataset\": {\"class_names\": [\"person\"]},\n",
    "                    },\n",
    "                }\n",
    "            ),\n",
    "        },\n",
    "    )\n",
    "    .raise_for_status()\n",
    "    .json()\n",
    ")\n",
    "\n",
    "print(f\"Created builder job: {job!r}\")\n",
    "\n",
    "job_id = job[\"id\"]\n",
    "\n",
    "print(\"Blocking until job is done...\")\n",
    "job = await utils.block_until_done(job_id)\n",
    "\n",
    "print(\"Builder job is done. Downloading artifacts\")\n",
    "artifacts = utils.download_artifacts(job)\n",
    "\n",
    "client.delete(f\"{config.JOBCONTROL_API_JOBS_ENDPOINT}/{job_id}\")\n",
    "\n",
    "getting_started_zip = artifacts[\"getting_started\"]\n",
    "\n",
    "with zf.ZipFile(io.BytesIO(getting_started_zip), \"r\") as archive:\n",
    "    binary_file_name = next(\n",
    "        name for name in archive.namelist() if name.endswith(\".bin\")\n",
    "    )\n",
    "    binary_file = archive.read(binary_file_name)\n",
    "\n",
    "assert open(\"./getting_started.zip\", \"wb\").write(getting_started_zip) > 0\n",
    "assert open(\"./binary.bin\", \"wb\").write(binary_file) > 0\n",
    "\n",
    "print(\"Succesfully produced final artifacts: `getting_started.zip` and `binary.bin`\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
