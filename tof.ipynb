{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToF demo\n",
    "\n",
    "This Jupyter notebook invokes the Vespucci jobcontrol-api to\n",
    "\n",
    "- Train the model for ToF\n",
    "- Generate the network `.c`/`.h` sources\n",
    "- Build the application firmware\n",
    "\n",
    "### Initial setup\n",
    "\n",
    "Dependencies are managed via `poetry`. You may install it with `pip install poetry`\n",
    "\n",
    "Then, install all dependencies simply by invoking `poetry install` in this directory. This will create a virtualenvironment and place it in this folder as `.venv`.\n",
    "\n",
    "Start a jupyter kernel in that environment and you're ready to run the notebook.\n",
    "\n",
    "You will also need API credentials for both Vespucci and the stm32ai developer cloud. Eventually these will be the same token, however for now the devcloud accepts only vespucci prod credentials. This examples runs on vespucci-dev.\n",
    "\n",
    "You'll need both tokens respectively at `./prod-token.txt` and `token.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration preamble\n",
    "import json\n",
    "import httpx\n",
    "import config\n",
    "import utils\n",
    "\n",
    "client = httpx.Client(timeout=300, headers=utils.headers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "This step will produce the `.h5` model artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset\", \"rb\") as dataset_file:\n",
    "    print(\"Creating training job\")\n",
    "    job = client.post(\n",
    "        config.JOBCONTROL_API_JOBS_ENDPOINT,\n",
    "        files={\n",
    "            \"uploadedFile\": dataset_file\n",
    "        },\n",
    "        data={\n",
    "            \"templateId\": config.TRAINING_JOB_TEMPLATE_ID,\n",
    "            \"runtimeInput\": json.dumps(\n",
    "                {\n",
    "                    \"config\": {},\n",
    "                }\n",
    "            )\n",
    "        }\n",
    "    ).raise_for_status().json()\n",
    "\n",
    "\n",
    "print(f\"Created training job: {job!r}\")\n",
    "\n",
    "job_id = job[\"id\"]\n",
    "\n",
    "print(\"Blocking until job is done...\")\n",
    "job = utils.block_until_done(job_id)\n",
    "\n",
    "print(\"Training job is done. Downloading artifacts\")\n",
    "artifacts = utils.download_artifacts(job)\n",
    "\n",
    "for key in artifacts:\n",
    "    print(f\"Writing {key}\")\n",
    "    with open(key, \"wb\") as file:\n",
    "        file.write(artifacts[key])\n",
    "\n",
    "# Ok for GC\n",
    "del artifacts\n",
    "client.delete(f\"{config.JOBCONTROL_API_JOBS_ENDPOINT}/{job_id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CubeAI\n",
    "\n",
    "This step will generate `.c`/`.h` NN sources by invoking the STM32 Developer cloud APIs.\n",
    "\n",
    "We'll download a zip containing said sources as well as the CubeAI runtime that will eventually be linked into the application firmware. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"best_model\", \"rb\") as model_file:\n",
    "    model = utils.NamedBuffer(\"model\", model_file.read())\n",
    "\n",
    "with open(\"prod_token.txt\", \"rb\") as token_file:\n",
    "    token = utils.NamedBuffer(\"token\", token_file.read())\n",
    "\n",
    "# devcloud API command\n",
    "command = {\n",
    "    \"command\": \"generate\",\n",
    "    \"parameters\": {\n",
    "        \"includeLibraryForSerie\": \"M4\",\n",
    "        \"allocateInputs\": True,\n",
    "        \"allocateOutputs\": True,\n",
    "        \"compression\": \"none\",\n",
    "        \"optimization\": \"balanced\"\n",
    "    },\n",
    "    \"version\": \"7.3.0\"\n",
    "}\n",
    "\n",
    "print(\"Creating CubeAI job\")\n",
    "job = client.post(\n",
    "    config.JOBCONTROL_API_JOBS_ENDPOINT,\n",
    "    files={\n",
    "        \"model\": model,\n",
    "        \"token\": token,\n",
    "    },\n",
    "    data={\n",
    "        \"templateId\": config.CUBEAI_JOB_TEMPLATE_ID,\n",
    "        \"runtimeInput\": json.dumps({\n",
    "            \"command\": command\n",
    "        })\n",
    "    }\n",
    ").raise_for_status().json()\n",
    "\n",
    "print(f\"Created CubeAI job: {job!r}\")\n",
    "\n",
    "job_id = job[\"id\"]\n",
    "\n",
    "print(\"Blocking until job is done...\")\n",
    "job = utils.block_until_done(job_id)\n",
    "\n",
    "print(\"CubeAI job is done. Downloading artifacts\")\n",
    "artifacts = utils.download_artifacts(job)\n",
    "\n",
    "for key in artifacts:\n",
    "    print(f\"Writing {key}\")\n",
    "    with open(key, \"wb\") as file:\n",
    "        file.write(artifacts[key])\n",
    "\n",
    "# Ok for GC\n",
    "del artifacts\n",
    "client.delete(f\"{config.JOBCONTROL_API_JOBS_ENDPOINT}/{job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building\n",
    "\n",
    "In this step we build the output NN sources into a deployment-ready application firmware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output\", \"rb\") as cubeai_output_file:\n",
    "    cubeai_output = utils.NamedBuffer(\"network\", cubeai_output_file.read())\n",
    "\n",
    "print(\"Creating builder job\")\n",
    "job = client.post(\n",
    "    config.JOBCONTROL_API_JOBS_ENDPOINT,\n",
    "    files={\n",
    "        \"network\": cubeai_output\n",
    "\n",
    "    },\n",
    "    data={\n",
    "        \"templateId\": config.COMPILATION_JOB_TEMPLATE_ID,\n",
    "        \"runtimeInput\": json.dumps({\n",
    "        })\n",
    "    }\n",
    ").raise_for_status().json()\n",
    "\n",
    "print(f\"Created builder job: {job!r}\")\n",
    "\n",
    "job_id = job[\"id\"]\n",
    "\n",
    "print(\"Blocking until job is done...\")\n",
    "job = utils.block_until_done(job_id)\n",
    "\n",
    "print(\"Builder job is done. Downloading artifacts\")\n",
    "artifacts = utils.download_artifacts(job)\n",
    "\n",
    "for key in artifacts:\n",
    "    print(f\"Writing {key}\")\n",
    "    with open(key, \"wb\") as file:\n",
    "        file.write(artifacts[key])\n",
    "\n",
    "# Ok for GC\n",
    "del artifacts\n",
    "client.delete(f\"{config.JOBCONTROL_API_JOBS_ENDPOINT}/{job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
