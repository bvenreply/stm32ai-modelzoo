{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToF demo\n",
    "\n",
    "This Jupyter notebook invokes the Vespucci jobcontrol-api to\n",
    "\n",
    "- Train the model for ToF\n",
    "- Benchmark the model and generate the network `.c`/`.h` sources\n",
    "- Build the application firmware\n",
    "\n",
    "### Initial setup\n",
    "\n",
    "Dependencies are managed via the `poetry` command. You may install it with `pip install poetry`\n",
    "\n",
    "Then, install all dependencies simply by invoking `poetry install` in this directory. This will create a virtual environment and place it in this folder as `.venv`.\n",
    "\n",
    "Start a jupyter kernel in that environment and you're ready to run the notebook.\n",
    "\n",
    "You will need API credentials for Vespucci. This example runs on vespucci-dev by default, so you should use a token generated for that environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration preamble\n",
    "import json\n",
    "import httpx\n",
    "import config\n",
    "import utils\n",
    "import asyncio\n",
    "\n",
    "from collections.abc import Awaitable\n",
    "\n",
    "client = httpx.Client(timeout=300, headers=utils.headers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "This step will produce the `.h5` model artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset\", \"rb\") as dataset_file:\n",
    "    print(\"Creating training job\")\n",
    "    job = client.post(\n",
    "        config.JOBCONTROL_API_JOBS_ENDPOINT,\n",
    "        files={\n",
    "            \"uploadedFile\": dataset_file\n",
    "        },\n",
    "        data={\n",
    "            \"templateId\": config.TRAINING_JOB_TEMPLATE_ID,\n",
    "            \"runtimeInput\": json.dumps(\n",
    "                {\n",
    "                    \"config\": {\n",
    "                        \"dataset\": {\n",
    "                            \"class_names\": [\n",
    "                                \"One\",\n",
    "                                \"Two\",\n",
    "                            ]\n",
    "                        },\n",
    "                        \"stm32ai\": {\n",
    "                            \"version\": \"8.1.0\"\n",
    "                        }\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "        }\n",
    "    ).raise_for_status().json()\n",
    "\n",
    "\n",
    "print(f\"Created training job: {job!r}\")\n",
    "\n",
    "job_id = job[\"id\"]\n",
    "\n",
    "print(\"Blocking until job is done...\")\n",
    "job = await utils.block_until_done(job_id)\n",
    "\n",
    "print(\"Training job is done. Downloading artifacts\")\n",
    "artifacts = utils.download_artifacts(job)\n",
    "\n",
    "for key in artifacts:\n",
    "    print(f\"Writing {key}\")\n",
    "    with open(key, \"wb\") as file:\n",
    "        file.write(artifacts[key])\n",
    "\n",
    "# Ok for GC\n",
    "del artifacts\n",
    "client.delete(f\"{config.JOBCONTROL_API_JOBS_ENDPOINT}/{job_id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking + Cube.AI\n",
    "\n",
    "This step will generate `.c`/`.h` NN sources by invoking the STM32 Developer cloud APIs.\n",
    "\n",
    "We'll download a zip containing said sources as well as the CubeAI runtime that will eventually be linked into the application firmware.\n",
    "\n",
    "Simultaneously, we'll dispatch the benchmarkinging job and display the inference time once it's been measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"best_model\", \"rb\") as model_file:\n",
    "    model = utils.NamedBuffer(\"model\", model_file.read())\n",
    "\n",
    "# devcloud API command\n",
    "generate_command = {\n",
    "    \"command\": \"generate\",\n",
    "    \"arguments\":{\n",
    "        \"options\": {\n",
    "            \"includeLibraryForSerie\": \"M4\",\n",
    "            \"includeLibraryForIde\": \"gcc\",\n",
    "            \"allocateInputs\": True,\n",
    "            \"allocateOutputs\": True,\n",
    "            \"compression\": \"none\",\n",
    "            \"optimization\": \"balanced\"\n",
    "        },\n",
    "    },\n",
    "    \"version\": \"8.1.0\"\n",
    "}\n",
    "\n",
    "print(\"Creating Cube.AI job\")\n",
    "generate_job = client.post(\n",
    "    config.JOBCONTROL_API_JOBS_ENDPOINT,\n",
    "    files={\n",
    "        \"model\": model,\n",
    "    },\n",
    "    data={\n",
    "        \"templateId\": config.CUBEAI_JOB_TEMPLATE_ID,\n",
    "        \"runtimeInput\": json.dumps({\n",
    "            \"command\": generate_command\n",
    "        })\n",
    "    }\n",
    ").raise_for_status().json()\n",
    "print(f\"Created CubeAI job: {generate_job!r}\")\n",
    "\n",
    "# devcloud API command\n",
    "benchmarking_command = {\n",
    "    \"command\": \"benchmark\",\n",
    "    \"arguments\":{\n",
    "        \"options\": {},\n",
    "        \"parameters\": {\n",
    "            \"board_name\": \"NUCLEO-F401RE\"\n",
    "        }\n",
    "    },\n",
    "    \"version\": \"8.1.0\"\n",
    "}\n",
    "\n",
    "print(\"Creating benchmarking job\")\n",
    "benchmarking_job = client.post(\n",
    "    config.JOBCONTROL_API_JOBS_ENDPOINT,\n",
    "    files={\n",
    "        \"model\": model,\n",
    "    },\n",
    "    data={\n",
    "        \"templateId\": config.BENCHMARKING_JOB_TEMPLATE_ID,\n",
    "        \"runtimeInput\": json.dumps({\n",
    "            \"command\": benchmarking_command\n",
    "        })\n",
    "    }\n",
    ").raise_for_status().json()\n",
    "print(f\"Created benchmarking job: {benchmarking_job!r}\")\n",
    "\n",
    "\n",
    "async def _generate_coro() -> Awaitable[None]:\n",
    "\n",
    "    global generate_job\n",
    "\n",
    "    job_id = generate_job[\"id\"]\n",
    "\n",
    "    generate_job = await utils.block_until_done(job_id)\n",
    "\n",
    "    print(\"CubeAI job is done. Downloading artifacts\")\n",
    "    artifacts = utils.download_artifacts(generate_job)\n",
    "\n",
    "    for key in artifacts:\n",
    "        print(f\"Writing {key}\")\n",
    "        with open(key, \"wb\") as file:\n",
    "            file.write(artifacts[key])\n",
    "\n",
    "    # Ok for GC\n",
    "    del artifacts\n",
    "    client.delete(f\"{config.JOBCONTROL_API_JOBS_ENDPOINT}/{job_id}\")\n",
    "\n",
    "\n",
    "async def _benchmarking_coro() -> Awaitable[None]:\n",
    "\n",
    "    global benchmarking_job\n",
    "\n",
    "    job_id = benchmarking_job[\"id\"]\n",
    "\n",
    "    benchmarking_job = await utils.block_until_done(job_id)\n",
    "\n",
    "    report = json.loads(benchmarking_job[\"outputs\"][\"parameters\"][\"benchmark_report\"])\n",
    "    print(f\"Benchmarking job is done. Inference time: {report['duration_ms']}ms\")\n",
    "\n",
    "\n",
    "    client.delete(f\"{config.JOBCONTROL_API_JOBS_ENDPOINT}/{job_id}\")\n",
    "\n",
    "await asyncio.wait((asyncio.create_task(_generate_coro()), asyncio.create_task(_benchmarking_coro())))\n",
    "\n",
    "print(\"Cube.AI and benchmarking done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building\n",
    "\n",
    "In this step we build the output NN sources into a deployment-ready application firmware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output\", \"rb\") as cubeai_output_file:\n",
    "    cubeai_output = utils.NamedBuffer(\"network\", cubeai_output_file.read())\n",
    "\n",
    "print(\"Creating builder job\")\n",
    "job = client.post(\n",
    "    config.JOBCONTROL_API_JOBS_ENDPOINT,\n",
    "    files={\n",
    "        \"network\": cubeai_output\n",
    "    },\n",
    "    data={\n",
    "        \"templateId\": config.COMPILATION_JOB_TEMPLATE_ID,\n",
    "        \"runtimeInput\": json.dumps({\n",
    "            \"config\": {\n",
    "                \"dataset\": {\n",
    "                    \"class_names\": [\n",
    "                        \"One\",\n",
    "                        \"Two\",\n",
    "                    ]\n",
    "                },\n",
    "                # \"stm32ai\": {\n",
    "                #     \"version\": \"8.1.0\"\n",
    "                # }\n",
    "            },\n",
    "        })\n",
    "    }\n",
    ").raise_for_status().json()\n",
    "\n",
    "print(f\"Created builder job: {job!r}\")\n",
    "\n",
    "job_id = job[\"id\"]\n",
    "\n",
    "print(\"Blocking until job is done...\")\n",
    "job = await utils.block_until_done(job_id)\n",
    "\n",
    "print(\"Builder job is done. Downloading artifacts\")\n",
    "artifacts = utils.download_artifacts(job)\n",
    "\n",
    "for key in artifacts:\n",
    "    print(f\"Writing {key}\")\n",
    "    with open(key, \"wb\") as file:\n",
    "        file.write(artifacts[key])\n",
    "\n",
    "# Ok for GC\n",
    "del artifacts\n",
    "client.delete(f\"{config.JOBCONTROL_API_JOBS_ENDPOINT}/{job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
