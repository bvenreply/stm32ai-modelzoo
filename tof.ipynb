{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToF demo\n",
    "\n",
    "This Jupyter notebook invokes the Vespucci jobcontrol-api to\n",
    "\n",
    "- Train the model for ToF\n",
    "- Generate the network `.c`/`.h` sources\n",
    "- Build the application firmware\n",
    "\n",
    "### Initial setup\n",
    "\n",
    "Dependencies are managed via `poetry`. You may install it with `pip install poetry`\n",
    "\n",
    "Then, install all dependencies simply by invoking `poetry install` in this directory. This will create a virtualenvironment and place it in this folder as `.venv`.\n",
    "\n",
    "Start a jupyter kernel in that environment and you're ready to run the notebook.\n",
    "\n",
    "You will also need API credentials for both Vespucci and the stm32ai developer cloud. Devcloud accepts vespucci tokens from all environments; his examples runs on vespucci-dev, so you should use a token generated for that environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration preamble\n",
    "import json\n",
    "import httpx\n",
    "import config\n",
    "import utils\n",
    "\n",
    "client = httpx.Client(timeout=300, headers=utils.headers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "This step will produce the `.h5` model artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset\", \"rb\") as dataset_file:\n",
    "    print(\"Creating training job\")\n",
    "    job = client.post(\n",
    "        config.JOBCONTROL_API_JOBS_ENDPOINT,\n",
    "        files={\n",
    "            \"uploadedFile\": dataset_file\n",
    "        },\n",
    "        data={\n",
    "            \"templateId\": config.TRAINING_JOB_TEMPLATE_ID,\n",
    "            \"runtimeInput\": json.dumps(\n",
    "                {\n",
    "                    \"config\": {\n",
    "                        \"dataset\": {\n",
    "                            \"class_names\": [\n",
    "                                \"One\",\n",
    "                                \"Two\",\n",
    "                                \"Three\",\n",
    "                                \"Four\"\n",
    "                            ]\n",
    "                        },\n",
    "                        # \"stm32ai\": {\n",
    "                        #     \"version\": \"8.1.0\"\n",
    "                        # }\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "        }\n",
    "    ).raise_for_status().json()\n",
    "\n",
    "\n",
    "print(f\"Created training job: {job!r}\")\n",
    "\n",
    "job_id = job[\"id\"]\n",
    "\n",
    "print(\"Blocking until job is done...\")\n",
    "job = await utils.block_until_done(job_id)\n",
    "\n",
    "print(\"Training job is done. Downloading artifacts\")\n",
    "artifacts = utils.download_artifacts(job)\n",
    "\n",
    "for key in artifacts:\n",
    "    print(f\"Writing {key}\")\n",
    "    with open(key, \"wb\") as file:\n",
    "        file.write(artifacts[key])\n",
    "\n",
    "# Ok for GC\n",
    "del artifacts\n",
    "client.delete(f\"{config.JOBCONTROL_API_JOBS_ENDPOINT}/{job_id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CubeAI\n",
    "\n",
    "This step will generate `.c`/`.h` NN sources by invoking the STM32 Developer cloud APIs.\n",
    "\n",
    "We'll download a zip containing said sources as well as the CubeAI runtime that will eventually be linked into the application firmware. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"best_model\", \"rb\") as model_file:\n",
    "    model = utils.NamedBuffer(\"model\", model_file.read())\n",
    "\n",
    "# devcloud API command\n",
    "command = {\n",
    "    \"command\": \"generate\",\n",
    "    \"arguments\":{\n",
    "        \"options\": {\n",
    "            \"includeLibraryForSerie\": \"M4\",\n",
    "            \"includeLibraryForIde\": \"gcc\",\n",
    "            \"allocateInputs\": True,\n",
    "            \"allocateOutputs\": True,\n",
    "            \"compression\": \"none\",\n",
    "            \"optimization\": \"balanced\"\n",
    "        },\n",
    "    },\n",
    "    \"version\": \"7.3.0\"\n",
    "}\n",
    "\n",
    "print(\"Creating CubeAI job\")\n",
    "job = client.post(\n",
    "    config.JOBCONTROL_API_JOBS_ENDPOINT,\n",
    "    files={\n",
    "        \"model\": model,\n",
    "    },\n",
    "    data={\n",
    "        \"templateId\": config.CUBEAI_JOB_TEMPLATE_ID,\n",
    "        \"runtimeInput\": json.dumps({\n",
    "            \"command\": command\n",
    "        })\n",
    "    }\n",
    ").raise_for_status().json()\n",
    "\n",
    "print(f\"Created CubeAI job: {job!r}\")\n",
    "\n",
    "job_id = job[\"id\"]\n",
    "\n",
    "print(\"Blocking until job is done...\")\n",
    "job = await utils.block_until_done(job_id)\n",
    "\n",
    "print(\"CubeAI job is done. Downloading artifacts\")\n",
    "artifacts = utils.download_artifacts(job)\n",
    "\n",
    "for key in artifacts:\n",
    "    print(f\"Writing {key}\")\n",
    "    with open(key, \"wb\") as file:\n",
    "        file.write(artifacts[key])\n",
    "\n",
    "# Ok for GC\n",
    "del artifacts\n",
    "client.delete(f\"{config.JOBCONTROL_API_JOBS_ENDPOINT}/{job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building\n",
    "\n",
    "In this step we build the output NN sources into a deployment-ready application firmware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output\", \"rb\") as cubeai_output_file:\n",
    "    cubeai_output = utils.NamedBuffer(\"network\", cubeai_output_file.read())\n",
    "\n",
    "print(\"Creating builder job\")\n",
    "job = client.post(\n",
    "    config.JOBCONTROL_API_JOBS_ENDPOINT,\n",
    "    files={\n",
    "        \"network\": cubeai_output\n",
    "    },\n",
    "    data={\n",
    "        \"templateId\": config.COMPILATION_JOB_TEMPLATE_ID,\n",
    "        \"runtimeInput\": json.dumps({\n",
    "            \"config\": {\n",
    "                \"dataset\": {\n",
    "                    \"class_names\": [\n",
    "                        \"One\",\n",
    "                        \"Two\",\n",
    "                        \"Three\",\n",
    "                        \"Four\"\n",
    "                    ]\n",
    "                },\n",
    "                # \"stm32ai\": {\n",
    "                #     \"version\": \"8.1.0\"\n",
    "                # }\n",
    "            },\n",
    "        })\n",
    "    }\n",
    ").raise_for_status().json()\n",
    "\n",
    "print(f\"Created builder job: {job!r}\")\n",
    "\n",
    "job_id = job[\"id\"]\n",
    "\n",
    "print(\"Blocking until job is done...\")\n",
    "job = await utils.block_until_done(job_id)\n",
    "\n",
    "print(\"Builder job is done. Downloading artifacts\")\n",
    "artifacts = utils.download_artifacts(job)\n",
    "\n",
    "for key in artifacts:\n",
    "    print(f\"Writing {key}\")\n",
    "    with open(key, \"wb\") as file:\n",
    "        file.write(artifacts[key])\n",
    "\n",
    "# Ok for GC\n",
    "del artifacts\n",
    "client.delete(f\"{config.JOBCONTROL_API_JOBS_ENDPOINT}/{job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
